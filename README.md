# Chat Code Interpreter

This is a Chat Code Interpreter application that allows you to interact with either OpenAI or Hugging Face language models for code generation and execution. You can upload CSV files, ask questions, and get code generated and executed.

## How to Run

1.  **Clone the repository:**
    ```bash
    git clone <your_repo_url>
    cd code-interpreter-chainlit
    ```

2.  **Set up environment variables:**
    *   Copy `.env.example` to `.env`.
    *   Replace `your_openai_api_key` with your actual OpenAI API key.
    *   Replace `your_huggingface_api_key` with your actual Hugging Face API key.

3.  **Build the Docker image:**
    ```bash
    docker build -t chat-code-interpreter .
    ```

4.  **Run the Docker container:**
    ```bash
    docker run -p 8000:8000 chat-code-interpreter
    ```

5.  Open your browser and go to `http://localhost:8000` to use the application.

## Features

-   Chat interface using Chainlit.
-   Model selection between OpenAI's `gpt-3.5-turbo` and Hugging Face's `Qwen2.5-Coder-32B-Instruct`.
-   Supports general chit-chat and data analysis tasks.
-   Processes uploaded CSV files for analysis.
-   Executes Python code generated by the model.
-   Outputs code execution results in the chat.
-   Uses the OpenAI Python library and Hugging Face Inference API without higher-level frameworks.
-   Dockerized for easy setup and deployment.
-   Modular design for better maintainability.

## Assumptions

-   Ensure Docker is installed on your machine.
-   You have an OpenAI API key or Hugging Face API key.
-   The api keys are stored in `.env` file under `OPENAI_API_KEY` and `HF_API_KEY` respectively. The relevant key must be present when selecting the model.

## Usage

1.  When you start the application, you will be prompted to select either OpenAI or Hugging Face model.
2.  After model selection, you can start sending messages.
3.  Upload CSV files to be used for the analysis.
4.  Ask data related or code related questions.
5.  The application will return the response of the model and if applicable it will also show the result of the code execution.

## Architecture

The application is structured into the following modules:

-   **`chat_agent.py`:** Base class for chat agents.
-  **`code_executor.py`**: Handles the execution of python code.
-  **`utils.py`**: Contains utility function such as API key loading.
-   **`ui.py`:** Contains the UI related code for the application